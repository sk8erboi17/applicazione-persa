# ðŸš€ Guida Completa â€” LaTeX-OCR Training + Inferenza C++

## Panoramica

```
Dataset scaricati (~10M campioni)
        â”‚
        â–¼
[STEP 1] Installa dipendenze Python
        â”‚
        â–¼
[STEP 2] Estrai immagini fusion dataset (root.rar â†’ cartella)
        â”‚
        â–¼
[STEP 3] Estrai HME100K (zip â†’ cartella)
        â”‚
        â–¼
[STEP 4] Prepara dataset unificato (genera train.pkl + val.pkl)
        â”‚                                    â± ~2-4 ore
        â–¼
[STEP 5] Lancia training PyTorch
        â”‚                                    â± ~24-72 ore
        â–¼
[STEP 6] Export modello â†’ GGUF
        â”‚
        â–¼
[STEP 7] Compila engine C++ (macOS o Linux)
        â”‚
        â–¼
[STEP 8] Inferenza C++ ðŸŽ‰
```

---

## STEP 1 â€” Installa dipendenze Python

```bash
cd ~/Desktop/LaTeX-OCR

# Dipendenze base del progetto
pip install -e .

# Dipendenze extra per il training potenziato
pip install datasets transformers tokenizers
pip install opencv-python-headless
pip install imagesize Levenshtein
pip install munch pyyaml tqdm wandb
pip install einops timm==0.5.4
pip install x_transformers==0.15.0
pip install torchtext
```

---

## STEP 2 â€” Estrai le immagini del fusion dataset

Il fusion dataset ha le immagini dentro `root.rar` (27GB). Devi estrarlo:

```bash
# Installa unrar se non ce l'hai
brew install rar     # macOS
# oppure: sudo apt install unrar   # Linux

# Trova il file rar
FUSION_DIR="$HOME/.cache/huggingface/hub/datasets--hoang-quoc-trung--fusion-image-to-latex-datasets/snapshots/82906d1f80b4bd36d6e05fa40ee051fb391effe3"

# Estrai (ci vorrÃ  un po')
cd /tmp
unrar x "$FUSION_DIR/root.rar" fusion_images/

# Controlla che ci siano le immagini
ls fusion_images/ | head -10
```

âš ï¸ **Servono ~30GB di spazio libero** per l'estrazione.

Se non vuoi estrarre tutto (o non hai spazio), puoi **saltare il fusion** e usare solo gli altri dataset (comunque ~2M campioni).

---

## STEP 3 â€” Estrai HME100K

```bash
# Estrai lo zip
mkdir -p ~/Desktop/LaTeX-OCR/data/hme100k
unzip ~/Downloads/hme100k.zip -d ~/Desktop/LaTeX-OCR/data/hme100k/

# Verifica
ls ~/Desktop/LaTeX-OCR/data/hme100k/images/ | wc -l
# Dovrebbe mostrare ~99000
```

---

## STEP 4 â€” Prepara il dataset unificato (â± ~2-4 ore)

Questo script scarica i dataset HuggingFace (giÃ  in cache), carica HME100K e fusion,
deduplica, genera il tokenizer BPE, e crea i .pkl per il training.

### Opzione A: TUTTI i dataset (con fusion â€” serve root.rar estratto)

```bash
cd ~/Desktop/LaTeX-OCR

FUSION_DIR="$HOME/.cache/huggingface/hub/datasets--hoang-quoc-trung--fusion-image-to-latex-datasets/snapshots/82906d1f80b4bd36d6e05fa40ee051fb391effe3"

python scripts/prepare_unified_dataset.py \
    --output data/unified \
    --fusion-dir "$FUSION_DIR" \
    --fusion-images /tmp/fusion_images \
    --hme100k-zip ~/Downloads/hme100k.zip \
    --hme100k-extract data/hme100k \
    --vocab-size 8000 \
    --hw-ratio 0.2
```

### Opzione B: SENZA fusion (se non vuoi estrarre 27GB)

```bash
cd ~/Desktop/LaTeX-OCR

python scripts/prepare_unified_dataset.py \
    --output data/unified \
    --hme100k-zip ~/Downloads/hme100k.zip \
    --hme100k-extract data/hme100k \
    --skip-datasets fusion \
    --vocab-size 8000 \
    --hw-ratio 0.2
```

### Output atteso:
```
DATASET PREPARATION COMPLETE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Train samples:  XXXXXX (printed + handwritten)
  Val samples:    XXXXX
  Tokenizer:      data/unified/tokenizer.json
  Sample weights: data/unified/sample_weights.json
  Train pkl:      data/unified/train.pkl
  Val pkl:        data/unified/val.pkl
```

---

## STEP 5 â€” Lancia il Training (â± ~24-72 ore)

### Su macOS M4 (MPS):

```bash
cd ~/Desktop/LaTeX-OCR

python -m pix2tex.train --config pix2tex/model/settings/config_large.yaml --no_cuda --debug
```

> `--no_cuda` forza il fallback a MPS su Mac.
> `--debug` disabilita wandb (se non l'hai configurato).

### Su Linux con CUDA:

```bash
cd ~/Desktop/LaTeX-OCR

python -m pix2tex.train --config pix2tex/model/settings/config_large.yaml
```

### Cosa aspettarsi:
- VedrÃ  automaticamente MPS (Mac) o CUDA (Linux)
- Stampa un riepilogo configurazione
- Ogni 2000 step valuta BLEU/ACC sul validation set
- Salva checkpoint quando migliora
- Puoi interromperlo con Ctrl+C (salva automatico dopo epoch 2)
- I checkpoint vanno in `checkpoints/latex_ocr_large/`

### Riprendere il training (se interrotto):

```bash
python -m pix2tex.train \
    --config pix2tex/model/settings/config_large.yaml \
    --no_cuda --debug \
    --resume
```

E nel config, imposta:
```yaml
load_chkpt: checkpoints/latex_ocr_large/latex_ocr_large_e05_step12345.pth
```

---

## STEP 6 â€” Export del modello a GGUF

Dopo il training, converti il miglior checkpoint in formato GGUF per il C++:

```bash
cd ~/Desktop/LaTeX-OCR

# FP16 (raccomandato â€” buon bilanciamento velocitÃ /precisione)
python scripts/export_gguf.py \
    --checkpoint checkpoints/latex_ocr_large/NOME_MIGLIOR_CHECKPOINT.pth \
    --config pix2tex/model/settings/config_large.yaml \
    --output latex_ocr_model.gguf \
    --dtype fp16

# Oppure Q8_0 (piÃ¹ veloce, leggermente meno preciso)
python scripts/export_gguf.py \
    --checkpoint checkpoints/latex_ocr_large/NOME_MIGLIOR_CHECKPOINT.pth \
    --config pix2tex/model/settings/config_large.yaml \
    --output latex_ocr_model_q8.gguf \
    --dtype q8_0
```

---

## STEP 7 â€” Compila l'engine C++

### macOS:

```bash
cd ~/Desktop/LaTeX-OCR/latex-ocr-cpp
chmod +x setup.sh
./setup.sh
```

### Linux:

```bash
# Installa OpenBLAS
sudo apt install libopenblas-dev cmake g++

cd ~/Desktop/LaTeX-OCR/latex-ocr-cpp
./setup.sh
```

Se ggml non si clona (firewall/proxy), scaricalo manualmente:
```bash
git clone --depth 1 https://github.com/ggml-org/ggml.git third_party/ggml
./setup.sh
```

---

## STEP 8 â€” Inferenza C++

```bash
cd ~/Desktop/LaTeX-OCR/latex-ocr-cpp/build

# Riconosci una formula da immagine
./latex_ocr \
    -m ../../latex_ocr_model.gguf \
    -t ../../data/unified/tokenizer.json \
    -i /path/to/formula.png

# Con parametri custom
./latex_ocr \
    -m ../../latex_ocr_model.gguf \
    -t ../../data/unified/tokenizer.json \
    -i formula.png \
    --temperature 0.1 \
    --max-tokens 256

# Solo CPU (no Metal GPU)
./latex_ocr \
    -m ../../latex_ocr_model.gguf \
    -t ../../data/unified/tokenizer.json \
    -i formula.png \
    --cpu --threads 8
```

---

## Riepilogo file creati/modificati

### Nuovi script Python:
| File | Scopo |
|------|-------|
| `scripts/prepare_unified_dataset.py` | Unifica tutti i dataset (HF + fusion + HME100K) |
| `scripts/convert_inkml.py` | Converte CROHME InkML â†’ PNG con OpenCV |
| `scripts/export_gguf.py` | Esporta modello PyTorch â†’ GGUF per C++ |

### File Python modificati:
| File | Modifiche |
|------|-----------|
| `pix2tex/train.py` | AMP, AdamW, cosine annealing, warmup, MPS, early stopping, weighted sampling |
| `pix2tex/model/settings/config_large.yaml` | Config training potenziato |

### Progetto C++ (inferenza):
```
latex-ocr-cpp/
â”œâ”€â”€ CMakeLists.txt          # Build cross-platform (Metal/OpenBLAS)
â”œâ”€â”€ setup.sh                # Script build automatico
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ latex_ocr.h         # API pubblica
â”‚   â”œâ”€â”€ tokenizer.h         # BPE tokenizer
â”‚   â”œâ”€â”€ image_preprocess.h  # Preprocessing immagini
â”‚   â”œâ”€â”€ encoder.h           # ResNet + ViT encoder (ggml)
â”‚   â”œâ”€â”€ decoder.h           # Decoder autoregressivo (ggml)
â”‚   â””â”€â”€ model.h             # Caricamento GGUF
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tokenizer.cpp
â”‚   â”œâ”€â”€ image_preprocess.cpp
â”‚   â”œâ”€â”€ encoder.cpp
â”‚   â”œâ”€â”€ decoder.cpp
â”‚   â”œâ”€â”€ model.cpp
â”‚   â”œâ”€â”€ latex_ocr.cpp
â”‚   â””â”€â”€ main.cpp            # CLI entry point
â””â”€â”€ third_party/
    â”œâ”€â”€ ggml/               # (clonato da setup.sh)
    â”œâ”€â”€ stb_image.h
    â”œâ”€â”€ stb_image_write.h
    â”œâ”€â”€ cJSON.h
    â””â”€â”€ cJSON.c
```

---

## Dataset utilizzati

| Dataset | Campioni | Tipo | Fonte |
|---------|----------|------|-------|
| fusion-image-to-latex | 3.4M train | Stampato + Manoscritto | HF (locale) |
| OleehyO/latex-formulas | 552k | Stampato | HF |
| UniMER-1M | 1.06M | Misto | HF |
| im2latex-100k | 68k | Stampato | HF |
| lukbl/LaTeX-OCR-dataset | 158k | Stampato | HF |
| HME100K | 99k | Manoscritto | Kaggle (locale) |
| **TOTALE** | **~5.3M** | | |

Il Weighted Random Sampler bilancia: **~20% manoscritto** per batch.
